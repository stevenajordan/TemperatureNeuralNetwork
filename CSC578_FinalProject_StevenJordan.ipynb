{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><center>Predicting Temperatures Using a Recurrent Neural Network</center></b>\n",
    "<center>CSC 578 Final Project | Section 910 Online</center>\n",
    "<center>Steven Jordan</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><strong><span style=\"text-decoration: underline;\">OBJECTIVE</span></strong></h4>\n",
    "<p>For this project, I built a recurrent neural network designed to predict the hourly temperature of a location, based on the climate conditions and temperatures of the twenty four hours preceding the prediction.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span style=\"text-decoration: underline;\"><strong>CONTENTS</strong></span></p>\n",
    "\n",
    "1. [DATA OVERVIEW](#DATA-OVERVIEW)\n",
    "2. [LIBRARY AND DATA IMPORTS](#LIBRARY-AND-DATA-IMPORTS)\n",
    "3. [EXPLORATORY DATA ANALYSIS](#EXPLORATORY-DATA-ANALYSIS)\n",
    "4. [DATA PRE-PROCESSING](#DATA-PRE--PROCESSING)\n",
    "5. [MODEL CONSTRUCTION](#MODEL-CONSTRUCTION)\n",
    "6. [MODEL EVALUTATION](#MODEL-EVALUATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span style=\"text-decoration: underline;\"><strong>DATA OVERVIEW</strong></span></p>\n",
    "<p>The dataset was provided by the class website and a more detailed description is available on the <a href=\"https://www.kaggle.com/c/csc-578-final-project-spring-2019/data\">Kaggle competition page</a>. It consists of hourly records of fourteen different climate and atmospheric attributes (e.g. temperature, atmospheric pressure, humidity, air density, etc.) that were recorded at the Max Planck Institute of Biogeochemistry in Jena, Germany from 2009 to 2016.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><u>LIBRARY AND DATA IMPORTS</u></strong></p>\n",
    "<p>Below are the libraries and modules used for this final version of the model. In other versions of the model (which had larger MAEs), there were additional modules imported - however they were removed to maximize the efficiency of this code. The data provided was already separated into a training set and test set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                                     # For easy dataframe management and processing\n",
    "import matplotlib.pyplot as plt                         # For plotting visualizations\n",
    "from sklearn.model_selection import train_test_split    # For creating the validation dataset\n",
    "from scipy import stats                                 # For normalizing the data\n",
    "import keras                                            # For building the RNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test data\n",
    "df_train = pd.read_csv(\"climate_hour_train.txt\")\n",
    "x_test = pd.read_csv(\"climate_Xtest.txt\", header = None)\n",
    "\n",
    "# Save the variable we're predicting \n",
    "y_variable = df_train['T (degC)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2009 01:00:00</td>\n",
       "      <td>996.50</td>\n",
       "      <td>-8.05</td>\n",
       "      <td>265.38</td>\n",
       "      <td>-8.78</td>\n",
       "      <td>94.4</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1307.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.63</td>\n",
       "      <td>192.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2009 02:00:00</td>\n",
       "      <td>996.62</td>\n",
       "      <td>-8.88</td>\n",
       "      <td>264.54</td>\n",
       "      <td>-9.77</td>\n",
       "      <td>93.2</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1312.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>190.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2009 03:00:00</td>\n",
       "      <td>996.84</td>\n",
       "      <td>-8.81</td>\n",
       "      <td>264.59</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>93.5</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1312.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>167.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "0  01.01.2009 01:00:00    996.50     -8.05    265.38        -8.78    94.4   \n",
       "1  01.01.2009 02:00:00    996.62     -8.88    264.54        -9.77    93.2   \n",
       "2  01.01.2009 03:00:00    996.84     -8.81    264.59        -9.66    93.5   \n",
       "\n",
       "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
       "0          3.33          3.14          0.19       1.96             3.15   \n",
       "1          3.12          2.90          0.21       1.81             2.91   \n",
       "2          3.13          2.93          0.20       1.83             2.94   \n",
       "\n",
       "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "0       1307.86      0.21           0.63     192.7  \n",
       "1       1312.25      0.25           0.63     190.3  \n",
       "2       1312.18      0.18           0.63     167.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the dataframe above - one can see that the training set is separated into a Date Time column, and fourteen different characteristics. The Date Time column will later be removed as it is not a predictive feature.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007.19</td>\n",
       "      <td>2.06</td>\n",
       "      <td>274.65</td>\n",
       "      <td>1.89</td>\n",
       "      <td>98.8</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>4.34</td>\n",
       "      <td>6.95</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.29</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.91</td>\n",
       "      <td>6.27</td>\n",
       "      <td>1268.31</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.61</td>\n",
       "      <td>157.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007.06</td>\n",
       "      <td>2.22</td>\n",
       "      <td>274.82</td>\n",
       "      <td>2.06</td>\n",
       "      <td>98.9</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.39</td>\n",
       "      <td>7.04</td>\n",
       "      <td>...</td>\n",
       "      <td>89.8</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.88</td>\n",
       "      <td>6.22</td>\n",
       "      <td>1266.15</td>\n",
       "      <td>2.74</td>\n",
       "      <td>4.37</td>\n",
       "      <td>157.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007.43</td>\n",
       "      <td>2.04</td>\n",
       "      <td>274.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>98.8</td>\n",
       "      <td>7.08</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.94</td>\n",
       "      <td>...</td>\n",
       "      <td>89.8</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.86</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1265.64</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.68</td>\n",
       "      <td>135.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1       2     3     4     5     6     7     8     9    ...   326  \\\n",
       "0  1007.19  2.06  274.65  1.89  98.8  7.09  7.00  0.09  4.34  6.95  ...  92.0   \n",
       "1  1007.06  2.22  274.82  2.06  98.9  7.17  7.09  0.08  4.39  7.04  ...  89.8   \n",
       "2  1007.43  2.04  274.61  1.87  98.8  7.08  6.99  0.08  4.33  6.94  ...  89.8   \n",
       "\n",
       "    327   328   329   330   331      332   333   334    335  \n",
       "0  6.83  6.29  0.55  3.91  6.27  1268.31  3.10  4.61  157.8  \n",
       "1  6.94  6.23  0.71  3.88  6.22  1266.15  2.74  4.37  157.9  \n",
       "2  6.91  6.20  0.70  3.86  6.20  1265.64  1.05  2.68  135.9  \n",
       "\n",
       "[3 rows x 336 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the dataframe above - one can see that the test set is pre-formatted to have the Date Time removed - and consists of 336 features - which are the 14 climate measurements concatenated over 24 hours (14 * 24 = 336). The training set will later be modified to match this format.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><u>EXPLORATORY DATA ANALYSIS</u></strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "      <td>52566.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>988.723002</td>\n",
       "      <td>9.172795</td>\n",
       "      <td>283.254265</td>\n",
       "      <td>4.779049</td>\n",
       "      <td>76.444300</td>\n",
       "      <td>13.357483</td>\n",
       "      <td>9.458133</td>\n",
       "      <td>3.899249</td>\n",
       "      <td>5.977212</td>\n",
       "      <td>9.568031</td>\n",
       "      <td>1216.718989</td>\n",
       "      <td>2.142170</td>\n",
       "      <td>3.539017</td>\n",
       "      <td>173.689628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.190684</td>\n",
       "      <td>8.533081</td>\n",
       "      <td>8.605048</td>\n",
       "      <td>6.922701</td>\n",
       "      <td>16.430164</td>\n",
       "      <td>7.572008</td>\n",
       "      <td>4.201679</td>\n",
       "      <td>4.723265</td>\n",
       "      <td>2.666892</td>\n",
       "      <td>4.253017</td>\n",
       "      <td>40.439912</td>\n",
       "      <td>1.530832</td>\n",
       "      <td>2.313246</td>\n",
       "      <td>87.251111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>918.500000</td>\n",
       "      <td>-22.760000</td>\n",
       "      <td>250.850000</td>\n",
       "      <td>-24.800000</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>1066.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>983.750000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>277.242500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>65.810000</td>\n",
       "      <td>7.640000</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>1188.082500</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>120.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>989.140000</td>\n",
       "      <td>9.310000</td>\n",
       "      <td>283.430000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>79.700000</td>\n",
       "      <td>11.740000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>5.595000</td>\n",
       "      <td>8.965000</td>\n",
       "      <td>1213.440000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>197.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>994.070000</td>\n",
       "      <td>15.280000</td>\n",
       "      <td>289.370000</td>\n",
       "      <td>10.030000</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>17.390000</td>\n",
       "      <td>12.320000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>7.780000</td>\n",
       "      <td>12.450000</td>\n",
       "      <td>1243.050000</td>\n",
       "      <td>2.880000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>233.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1012.740000</td>\n",
       "      <td>35.480000</td>\n",
       "      <td>309.690000</td>\n",
       "      <td>22.940000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>57.800000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>41.710000</td>\n",
       "      <td>17.940000</td>\n",
       "      <td>28.530000</td>\n",
       "      <td>1392.560000</td>\n",
       "      <td>12.580000</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p (mbar)      T (degC)      Tpot (K)   Tdew (degC)        rh (%)  \\\n",
       "count  52566.000000  52566.000000  52566.000000  52566.000000  52566.000000   \n",
       "mean     988.723002      9.172795    283.254265      4.779049     76.444300   \n",
       "std        8.190684      8.533081      8.605048      6.922701     16.430164   \n",
       "min      918.500000    -22.760000    250.850000    -24.800000     13.060000   \n",
       "25%      983.750000      3.110000    277.242500      0.130000     65.810000   \n",
       "50%      989.140000      9.310000    283.430000      5.200000     79.700000   \n",
       "75%      994.070000     15.280000    289.370000     10.030000     89.800000   \n",
       "max     1012.740000     35.480000    309.690000     22.940000    100.000000   \n",
       "\n",
       "       VPmax (mbar)  VPact (mbar)  VPdef (mbar)     sh (g/kg)  \\\n",
       "count  52566.000000  52566.000000  52566.000000  52566.000000   \n",
       "mean      13.357483      9.458133      3.899249      5.977212   \n",
       "std        7.572008      4.201679      4.723265      2.666892   \n",
       "min        0.970000      0.810000      0.000000      0.510000   \n",
       "25%        7.640000      6.170000      0.810000      3.890000   \n",
       "50%       11.740000      8.850000      2.090000      5.595000   \n",
       "75%       17.390000     12.320000      5.130000      7.780000   \n",
       "max       57.800000     28.040000     41.710000     17.940000   \n",
       "\n",
       "       H2OC (mmol/mol)  rho (g/m**3)      wv (m/s)  max. wv (m/s)  \\\n",
       "count     52566.000000  52566.000000  52566.000000   52566.000000   \n",
       "mean          9.568031   1216.718989      2.142170       3.539017   \n",
       "std           4.253017     40.439912      1.530832       2.313246   \n",
       "min           0.810000   1066.190000      0.000000       0.000000   \n",
       "25%           6.240000   1188.082500      1.010000       1.800000   \n",
       "50%           8.965000   1213.440000      1.790000       3.000000   \n",
       "75%          12.450000   1243.050000      2.880000       4.750000   \n",
       "max          28.530000   1392.560000     12.580000      20.330000   \n",
       "\n",
       "           wd (deg)  \n",
       "count  52566.000000  \n",
       "mean     173.689628  \n",
       "std       87.251111  \n",
       "min        0.000000  \n",
       "25%      120.800000  \n",
       "50%      197.100000  \n",
       "75%      233.800000  \n",
       "max      360.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>One can see in the data description above, that the attribute values vary enormously in scale - from as low as -22.76 to as high as 1012.74 - so scaling the attributes will be essential before the construction of the neural network. The images below were generated via Tableau.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\"><strong>CLIMATE ATTRIBUTES OVER TIME (HOURLY)</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src=\"https://lh4.googleusercontent.com/61F0bWaptto2W7XQVKUS0X8-dm2TgFixNHvx6epHHL63g5idMIuGe2Hdppljx6SlKxOZPEgTGtKhROKcky2q=w1280-h881-rw\" alt=\"\" width=\"976\" height=\"478\" /></p>\n",
    "<p><img src=\"https://lh5.googleusercontent.com/mWw2-u3uC_DIBgcoZUJX3kFBawIdAT6VEXbEHpfRbo1d4vkwIp154d60FkFaBJzpTja-YDNowi9QgcEg314u=w1280-h881-rw\" alt=\"\" width=\"976\" height=\"491\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When one plots the data over time on an hour-by-hour basis, one can see in the data above that the scales vary widely - and some appear to be cyclical each year. One attribute - wind direction - varies so incredibly much on an hour by hour basis, that it appears to almost be noise.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\"><strong>CLIMATE ATTRIBUTES OVER TIME (MONTHLY AGGREGATE)</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src=\"https://lh6.googleusercontent.com/kgUYtbkJMO-v31D27dTWpqVDuMNCvRSWJBwzGdFucA1Ft13drtpAo_ZNGoaSVVKU4niSJjXhflz1BXpDRGnF=w1280-h881-rw\" alt=\"\" width=\"976\" height=\"478\" /></p>\n",
    "<p><img src=\"https://lh3.googleusercontent.com/CHPuKSSxy54_yCXI6_x3nefNby7iiSie1VmND0zMrX50ZmMg6JGj8pUYM7Y19iZicVvhoHUz7INfLCMT1o22=w1280-h881-rw\" alt=\"\" width=\"976\" height=\"478\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When aggregating by month, the yearly patterns become a lot more clear - even in wind direction, indicating that it's not just noise, but that there is a seasonal aspect to it.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left;\"><span style=\"text-decoration: underline;\"><strong>DATA PRE-PROCESSING</strong></span></p>\n",
    "<p>The x_training dataset is pre-processed by removing the Time Date variable, and then each row is transformed to be a concatated set of itself and the attributes of 24 hours preceding. Any rows with null values are removed. This decreases the size of the training set to be 52,542 rows. Then the \"current\" hour attributes are removed. &nbsp;</p>\n",
    "<p>The y_training set has the first 24 rows removed - which correspond to the 24 rows removed from the x_training set. So now, each y-value temperature shares the index of the x-row with the attributes of the 24 hours preceding it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (52542, 336)\n",
      "y_train shape:  (52542,)\n"
     ]
    }
   ],
   "source": [
    "# Add in the additional columns of the past 24 hours\n",
    "full_train = [df_train.iloc[:,1:].shift((24-1*i)) for i in range(24)]\n",
    "full_train = pd.concat([df_train.iloc[:,1:], *full_train], axis=1)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "full_train = full_train.dropna()\n",
    "\n",
    "# Drop the \"current hour\" values, since we only want the 24 hours preceding.\n",
    "x_train = full_train.iloc[:,14:]\n",
    "print('x_train shape: ', x_train.shape)\n",
    "\n",
    "# First 24 rows of the y variables are removed to match the x_training set\n",
    "y_train = y_variable.iloc[24:]\n",
    "print('y_train shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, because the values of the attribute vary dramatically in scale, the training and test sets are now normalized to their z-values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training and test sets\n",
    "x_test = x_test.values\n",
    "x_test = stats.zscore(x_test)\n",
    "\n",
    "x_train = x_train.values\n",
    "x_train = stats.zscore(x_train)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_train = stats.zscore(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Because I want to track and visualize the my model with a validation set, the below code splits 20% of the training set into validation. The sets are then reshaped to be 3D for use in the RNN.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training into training and validation\n",
    "x_training, x_validation, y_training, y_validation = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the sets to be 3D\n",
    "x_training = x_training.reshape((x_training.shape[0], 24, 14))\n",
    "x_validation = x_validation.reshape((x_validation.shape[0], 24, 14))\n",
    "x_testing = x_test.reshape((x_test.shape[0], 24, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left;\"><span style=\"text-decoration: underline;\"><strong>MODEL CONSTRUCTION</strong></span></p>\n",
    "<p>Below you see the construction of an extremely simple LSTM neural network, with 10 units, no hidden layers, no recurrent dropout, statefulness, or attached CNNs. Despite my best efforts (and all of my expectations), the only modification that reduced the Mean Average Error of the model was decreasing the number of units - from 50 to 10.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10)                1000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,011\n",
      "Trainable params: 1,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Design the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(x_training.shape[1], x_training.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42033 samples, validate on 10509 samples\n",
      "Epoch 1/30\n",
      "42033/42033 [==============================] - 26s 618us/step - loss: 0.1606 - val_loss: 0.0828\n",
      "Epoch 2/30\n",
      "42033/42033 [==============================] - 25s 590us/step - loss: 0.0723 - val_loss: 0.0669\n",
      "Epoch 3/30\n",
      "42033/42033 [==============================] - 26s 621us/step - loss: 0.0643 - val_loss: 0.0632\n",
      "Epoch 4/30\n",
      "42033/42033 [==============================] - 25s 600us/step - loss: 0.0619 - val_loss: 0.0622\n",
      "Epoch 5/30\n",
      "42033/42033 [==============================] - 25s 592us/step - loss: 0.0608 - val_loss: 0.0621\n",
      "Epoch 6/30\n",
      "42033/42033 [==============================] - 26s 607us/step - loss: 0.0603 - val_loss: 0.0612\n",
      "Epoch 7/30\n",
      "42033/42033 [==============================] - 28s 658us/step - loss: 0.0598 - val_loss: 0.0606\n",
      "Epoch 8/30\n",
      "42033/42033 [==============================] - 27s 637us/step - loss: 0.0593 - val_loss: 0.0603\n",
      "Epoch 9/30\n",
      "42033/42033 [==============================] - 25s 599us/step - loss: 0.0588 - val_loss: 0.0605\n",
      "Epoch 10/30\n",
      "42033/42033 [==============================] - 23s 552us/step - loss: 0.0584 - val_loss: 0.0589\n",
      "Epoch 11/30\n",
      "42033/42033 [==============================] - 23s 558us/step - loss: 0.0579 - val_loss: 0.0591\n",
      "Epoch 12/30\n",
      "42033/42033 [==============================] - 23s 548us/step - loss: 0.0575 - val_loss: 0.0584\n",
      "Epoch 13/30\n",
      "42033/42033 [==============================] - 24s 560us/step - loss: 0.0572 - val_loss: 0.0582\n",
      "Epoch 14/30\n",
      "42033/42033 [==============================] - 23s 558us/step - loss: 0.0569 - val_loss: 0.0578\n",
      "Epoch 15/30\n",
      "42033/42033 [==============================] - 24s 572us/step - loss: 0.0567 - val_loss: 0.0575\n",
      "Epoch 16/30\n",
      "42033/42033 [==============================] - 24s 568us/step - loss: 0.0564 - val_loss: 0.0573\n",
      "Epoch 17/30\n",
      "42033/42033 [==============================] - 24s 560us/step - loss: 0.0563 - val_loss: 0.0570\n",
      "Epoch 18/30\n",
      "42033/42033 [==============================] - 23s 553us/step - loss: 0.0561 - val_loss: 0.0567\n",
      "Epoch 19/30\n",
      "42033/42033 [==============================] - 25s 584us/step - loss: 0.0560 - val_loss: 0.0566\n",
      "Epoch 20/30\n",
      "42033/42033 [==============================] - 23s 556us/step - loss: 0.0559 - val_loss: 0.0568\n",
      "Epoch 21/30\n",
      "42033/42033 [==============================] - 23s 550us/step - loss: 0.0558 - val_loss: 0.0570\n",
      "Epoch 22/30\n",
      "42033/42033 [==============================] - 24s 567us/step - loss: 0.0556 - val_loss: 0.0565\n",
      "Epoch 23/30\n",
      "42033/42033 [==============================] - 24s 565us/step - loss: 0.0555 - val_loss: 0.0571\n",
      "Epoch 24/30\n",
      "42033/42033 [==============================] - 23s 556us/step - loss: 0.0555 - val_loss: 0.0566\n",
      "Epoch 25/30\n",
      "42033/42033 [==============================] - 24s 560us/step - loss: 0.0554 - val_loss: 0.0563\n",
      "Epoch 26/30\n",
      "42033/42033 [==============================] - 24s 573us/step - loss: 0.0553 - val_loss: 0.0561\n",
      "Epoch 27/30\n",
      "42033/42033 [==============================] - 24s 563us/step - loss: 0.0553 - val_loss: 0.0561\n",
      "Epoch 28/30\n",
      "42033/42033 [==============================] - 23s 559us/step - loss: 0.0552 - val_loss: 0.0562\n",
      "Epoch 29/30\n",
      "42033/42033 [==============================] - 24s 566us/step - loss: 0.0552 - val_loss: 0.0562\n",
      "Epoch 30/30\n",
      "42033/42033 [==============================] - 23s 556us/step - loss: 0.0551 - val_loss: 0.0562\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuYXXV97/H3d9/3XDNJJpALmIBRQkIIIYmcogjF0qAFvAQJaI/4tKWVclqttlJPjwh9PIe2FmlPqYpHrLYopVGUtlFECxW80CQIISFcAgQzCSST22Tu+/Y9f6w118xMdpJJJrPW5/U8+1lrr9v8VjZ81lq/tdbvZ+6OiIjEQ2KiCyAiIieOQl9EJEYU+iIiMaLQFxGJEYW+iEiMKPRFRGJEoS8iEiMKfRGRGFHoi4jESGqiCzDc9OnTfe7cuRNdDBGRSWXDhg173L35cMuddKE/d+5c1q9fP9HFEBGZVMzs1WqWU/WOiEiMKPRFRGJEoS8iEiMnXZ2+iERLsVikpaWFnp6eiS5KJORyOebMmUM6nT6q9RX6InJctbS0UF9fz9y5czGziS7OpObu7N27l5aWFubNm3dU21D1jogcVz09PUybNk2BPw7MjGnTph3TVVNVoW9mK83seTPbamY3jzD/IjN70sxKZrZq2LzTzewHZrbFzJ41s7lHXVoRmZQU+OPnWP8tDxv6ZpYE7gIuB84GrjWzs4ct9kvgeuAbI2zi68BfufsCYAWw+1gKPJr2niKff/gFntp+4HhsXkQkEqo5018BbHX3l929ANwHXDV4AXff5u4bgcrg6eHBIeXuD4fLdbh71/gUfahyxfmbH73Ihlf3H4/Ni8gkdeDAAf7+7//+iNd75zvfyYED0TuJrCb0ZwPbB31vCadV403AATP7tpn9wsz+KrxyGMLMbjCz9Wa2vrW1tcpND1WXDe5JH+wuHtX6IhJNo4V+uVwec721a9cyZcqU41WsCVNN6I9UgeRVbj8FvA34BLAcOIOgGmjoxtzvdvdl7r6sufmwTUeM/IeSCeqyKQ72KPRFZMDNN9/MSy+9xJIlS1i+fDmXXHIJ1113Heeccw4A7373uzn//PNZuHAhd999d/96c+fOZc+ePWzbto0FCxbwO7/zOyxcuJDLLruM7u7uidqdY1bNI5stwGmDvs8Bdla5/RbgF+7+MoCZfQe4APjKkRSyWo35NAe7S8dj0yIyDm791808u/PguG7z7FkN3HLFwlHn33777WzatImnnnqKRx99lHe9611s2rSp/5HHe+65h6lTp9Ld3c3y5ct53/vex7Rp04Zs48UXX+Sb3/wmX/7yl3n/+9/Pt771LT74wQ+O636cKNWc6a8D5pvZPDPLAKuBB6vc/jqgycz6Tt9/FXj2yItZnfpcijZV74jIGFasWDHkGfe//du/5dxzz+WCCy5g+/btvPjii4esM2/ePJYsWQLA+eefz7Zt205UccfdYc/03b1kZjcBDwFJ4B5332xmtwHr3f1BM1sOPAA0AVeY2a3uvtDdy2b2CeBHFjxntAH48vHamYZ8WtU7Iiexsc7IT5Ta2tr+8UcffZQf/vCH/OxnP6OmpoaLL754xGfgs9ls/3gymYx89Q7uvhZYO2zapweNryOo9hlp3YeBxcdQxqo15NK07D8uDweJyCRVX19Pe3v7iPPa2tpoamqipqaG5557jp///OcnuHQnXqSaYWjMp9nymur0RWTAtGnTuPDCC1m0aBH5fJ5TTjmlf97KlSv54he/yOLFi3nzm9/MBRdcMIElPTEiFfoNedXpi8ihvvGNkd4bDaptvve97404r6/efvr06WzatKl/+ic+8YlxL9+JFKm2dxpyaTp6S5TKlcMvLCISQ9EK/XzQ1GhHr6p4RERGEqnQbwxDX8/qi4iMLFKh35ALm2LQY5siIiOKVuiHZ/q6mSsiMrJohX6ur3pHoS8iMpJohX5e1Tsicmzq6uoA2LlzJ6tWrRpxmYsvvpj169ePuZ0777yTrq6Bl0VPlqaaIxX6upErIuNl1qxZrFmz5qjXHx76J0tTzZEK/dpMioSpTl9EBnzyk58c0p7+Zz7zGW699VYuvfRSli5dyjnnnMN3v/vdQ9bbtm0bixYtAqC7u5vVq1ezePFirrnmmiFt73zkIx9h2bJlLFy4kFtuuQUIGnHbuXMnl1xyCZdccgkw0FQzwB133MGiRYtYtGgRd955Z//fOxFNOEfqjdxEwqjPqdE1kZPW926G158Z322eeg5cfvuos1evXs1HP/pRbrzxRgDuv/9+vv/97/Oxj32MhoYG9uzZwwUXXMCVV145av+zX/jCF6ipqWHjxo1s3LiRpUuX9s/77Gc/y9SpUymXy1x66aVs3LiRP/iDP+COO+7gkUceYfr06UO2tWHDBr761a/yxBNP4O685S1v4e1vfztNTU0npAnnSJ3pQ1Cvrxu5ItLnvPPOY/fu3ezcuZOnn36apqYmZs6cyac+9SkWL17MO97xDnbs2MGuXbtG3caPf/zj/vBdvHgxixcPtCF5//33s3TpUs477zw2b97Ms8+O3Xr8448/znve8x5qa2upq6vjve99L4899hhwYppwjtSZPoQdqfSoTl/kpDTGGfnxtGrVKtasWcPrr7/O6tWruffee2ltbWXDhg2k02nmzp07YpPKg410FfDKK6/wuc99jnXr1tHU1MT1119/2O24j97x4Ilowjl6Z/q5tOr0RWSI1atXc99997FmzRpWrVpFW1sbM2bMIJ1O88gjj/Dqq6+Ouf5FF13EvffeC8CmTZvYuHEjAAcPHqS2tpbGxkZ27do1pPG20Zp0vuiii/jOd75DV1cXnZ2dPPDAA7ztbW8bx70dW+TO9BtyaV5q7ZjoYojISWThwoW0t7cze/ZsZs6cyQc+8AGuuOIKli1bxpIlSzjrrLPGXP8jH/kIH/7wh1m8eDFLlixhxYoVAJx77rmcd955LFy4kDPOOIMLL7ywf50bbriByy+/nJkzZ/LII4/0T1+6dCnXX399/zZ++7d/m/POO++E9cZlY11qTIRly5b54Z5/HcufrHma/3yhlSc+9Y5xLJWIHK0tW7awYMGCiS5GpIz0b2pmG9x92eHWjVz1jjpHFxEZXeRCvyGXprtYplBSm/oiIsNFL/T73srVs/oiJ42TrRp5MjvWf8sIhn7Y/o6e4BE5KeRyOfbu3avgHwfuzt69e8nlcke9jcg9vdPf/o6e1Rc5KcyZM4eWlhZaW1snuiiRkMvlmDNnzlGvH7nQV/PKIieXdDrNvHnzJroYEopg9Y46UhERGU30Qj+nG7kiIqOJXuj338hVnb6IyHCRC/18Okk6aTrTFxEZQeRC38zU6JqIyCiqCn0zW2lmz5vZVjO7eYT5F5nZk2ZWMrNDOpU0swYz22FmfzcehT6chnxaT++IiIzgsKFvZkngLuBy4GzgWjM7e9hivwSuB74xymb+HPjPoy/mkWnIpfScvojICKo5018BbHX3l929ANwHXDV4AXff5u4bgUMavDGz84FTgB+MQ3mrojN9EZGRVRP6s4Htg763hNMOy8wSwF8Df3zkRTt6Cn0RkZFVE/oj9RRcbSMaNwJr3X37WAuZ2Q1mtt7M1o/Hq9oN6hxdRGRE1TTD0AKcNuj7HGBnldv/b8DbzOxGoA7ImFmHuw+5GezudwN3Q9CJSpXbHlXQOXoJdx+1d3sRkTiqJvTXAfPNbB6wA1gNXFfNxt39A33jZnY9sGx44B8Pjfk0hXKF3lKFXDp5vP+ciMikcdjqHXcvATcBDwFbgPvdfbOZ3WZmVwKY2XIzawGuBr5kZpuPZ6EPR42uiYiMrKpWNt19LbB22LRPDxpfR1DtM9Y2/gH4hyMu4VEY3OjajIajb3daRCRqIvdGLgTP6YMaXRMRGS6Sod/fkYoaXRMRGSKSoa9+ckVERhbN0M+pIxURkZFEMvTrc+ocXURkJJEM/Vw6STaVUKNrIiLDRDL0IbiZqzN9EZGhIhv6DXl1pCIiMlx0Qz+X0tM7IiLDRDf082k9py8iMkxkQ78xr+aVRUSGi2zoN+R0I1dEZLjohn4+6CfX/Zib5xcRiYzohn4uTbnidBbKE10UEZGTRmRDf6DRNVXxiIj0iWzoq9E1EZFDRTf0+xpd61Loi4j0iW7o5/s6UtGz+iIifSIb+qrTFxE5VGRDv79zdNXpi4j0i2zo97Wpr0bXREQGRDb0U8kEtZmk2t8RERkksqEPan9HRGS4SId+gzpSEREZItqhn1NHKiIig0U79MNG10REJBDt0FfzyiIiQ0Q79HUjV0RkiMiHfkdviUpFbeqLiECVoW9mK83seTPbamY3jzD/IjN70sxKZrZq0PQlZvYzM9tsZhvN7JrxLPzhNORSuEO76vVFRIAqQt/MksBdwOXA2cC1Znb2sMV+CVwPfGPY9C7gv7v7QmAlcKeZTTnWQldLzSuLiAyVqmKZFcBWd38ZwMzuA64Cnu1bwN23hfMqg1d09xcGje80s91AM3DgmEtehb5G19q6i5x2Iv6giMhJrprqndnA9kHfW8JpR8TMVgAZ4KUR5t1gZuvNbH1ra+uRbnpUanRNRGSoakLfRph2RHdGzWwm8I/Ah929Mny+u9/t7svcfVlzc/ORbHpM/W3q67FNERGgutBvgSG1I3OAndX+ATNrAP4d+DN3//mRFe/Y9J/pq9E1ERGgutBfB8w3s3lmlgFWAw9Ws/Fw+QeAr7v7vxx9MY9OY42qd0REBjts6Lt7CbgJeAjYAtzv7pvN7DYzuxLAzJabWQtwNfAlM9scrv5+4CLgejN7KvwsOS57MoK6TAozVe+IiPSp5ukd3H0tsHbYtE8PGl9HUO0zfL1/Av7pGMt41BIJoz6bUqNrIiKhSL+RC31NMahOX0QEYhD6jWpTX0SkX+RDvyGnRtdERPpEP/TzKT2yKSISin7oq/csEZF+0Q99takvItIv8qHfmE/TVShTLB/S+oOISOxEPvQbcsGrCGpTX0QkDqE/qHllEZG4i37o9ze6ptAXEYl86KvRNRGRAZEPfTWvLCIyIPqhH3akojp9EZE4hL66TBQR6Rf50K/JJEklTDdyRUSIQeibmd7KFREJRT70IXhBq003ckVEYhL6alNfRASISeg3qnpHRASISeg35HSmLyICcQn9fEr95IqIEJfQV0cqIiJAXEI/n6ZQqtBTLE90UUREJlRsQh/0Vq6ISDxCP+xIRY2uiUjcxSP01ZGKiAgQl9BXo2siIkBMQr8xr96zRESgytA3s5Vm9ryZbTWzm0eYf5GZPWlmJTNbNWzeh8zsxfDzofEq+JHoa1Nfz+qLSNwdNvTNLAncBVwOnA1ca2ZnD1vsl8D1wDeGrTsVuAV4C7ACuMXMmo692EdG/eSKiASqOdNfAWx195fdvQDcB1w1eAF33+buG4HKsHV/HXjY3fe5+37gYWDlOJT7iOTSSTKphEJfRGKvmtCfDWwf9L0lnFaNY1l3XKnRNRGR6kLfRpjmVW6/qnXN7AYzW29m61tbW6vc9JFpyKX0nL6IxF41od8CnDbo+xxgZ5Xbr2pdd7/b3Ze5+7Lm5uYqN31k1HuWiEh1ob8OmG9m88wsA6wGHqxy+w8Bl5lZU3gD97Jw2gmnRtdERKoIfXcvATcRhPUW4H5332xmt5nZlQBmttzMWoCrgS+Z2eZw3X3AnxMcONYBt4XTTrhG9Z4lIkKqmoXcfS2wdti0Tw8aX0dQdTPSuvcA9xxDGceF2tQXEYnJG7kw0HuWe7X3oEVEoic+oZ9PU6o4XQW1qS8i8RWf0FejayIi8Qn9gUbXVK8vIvEVm9AfaHRNZ/oiEl/xCf2weqetS6EvIvEVn9BXP7kiIvEJfXWkIiISo9Cvz6kjFRGR2IR+OpmgJpNU+zsiEmuxCX0YeCtXRCSuYhX66khFROIuVqHfkFdHKiISb/EK/ZzO9EUk3uIV+nl1pCIi8Rar0FdHKiISd7EK/YZcivbeEpWK2tQXkXiKV+jn07hDR0E3c0UknuIV+mp0TURiLl6hr0bXRCTmYhb6Yfs7elZfRGIqXqGvLhNFJOZiFfp9zSvrWX0RiatYhX7/mb5CX0RiKlahX59LYaY29UUkvmIV+omEUZdN6UxfRGIrOqHf1gJfuwJe/OGYi6nRNRGJs+iEfu0MeG0jPHP/mIs1qP0dEYmx6IR+KgNnXwVb/g0KXaMu1qg29UUkxqoKfTNbaWbPm9lWM7t5hPlZM/vncP4TZjY3nJ42s6+Z2TNmtsXM/nR8iz/MOVdDsRNe+N6oi6h6R0Ti7LChb2ZJ4C7gcuBs4FozO3vYYr8F7Hf3NwKfB/4inH41kHX3c4Dzgd/tOyAcF2/4FaifBc+sGXURVe+ISJxVc6a/Atjq7i+7ewG4D7hq2DJXAV8Lx9cAl5qZAQ7UmlkKyAMF4OC4lHwkiSQsei+8+DB07RtxkYacOlIRkfiqJvRnA9sHfW8Jp424jLuXgDZgGsEBoBN4Dfgl8Dl3PySNzewGM1tvZutbW1uPeCeGOOdqqBRhy4Mjzm7Mp+kslCmVK8f2d0REJqFqQt9GmDa8F5LRllkBlIFZwDzg42Z2xiELut/t7svcfVlzc3MVRRrDzHNh2vxRq3j6Gl1r1wtaIhJD1YR+C3DaoO9zgJ2jLRNW5TQC+4DrgO+7e9HddwM/AZYda6HHZBac7W97HNp2HDJbja6JSJxVE/rrgPlmNs/MMsBqYHjdyYPAh8LxVcB/uLsTVOn8qgVqgQuA58an6GM4ZxXgsPnbh8xqUKNrIhJjhw39sI7+JuAhYAtwv7tvNrPbzOzKcLGvANPMbCvwR0DfY513AXXAJoKDx1fdfeM478Ohpp0Js5bCM/9yyKy+ljb1rL6IxFGqmoXcfS2wdti0Tw8a7yF4PHP4eh0jTT8hzrkaHvpTaH0Bmt/UP7m/IxVV74hIDEXnjdzhFr0XMNg09IaumlcWkTiLbujXnwrzLgqqeHzgYSP1kysicRbd0Iegimffy7Dzyf5JtZkkyYTpRq6IxFK0Q3/BFZDMDHlm38xoyKnRNRGJp2iHfn4KzL8MNn0LKuX+yQ15NbomIvEU7dCHoIqnYxdse6x/UkNOja6JSDxFP/Tf9OuQqR/yzH5DPqU6fRGJpeiHfjof1O0/+69Q7AGCF7TUObqIxFH0Qx+CZhl622DrwwA05jPsauuhXfX6IhIz8Qj9eW+H2ub+Kp5V58+hs1Di1n99doILJiJyYsUj9JMpWPheeP770HOQ89/QxE2XvJE1G1pY+8xrE106EZETJh6hD7D4/VDuhef+DYD/cel8zp3TyKceeIbX23omuHAiIidGfEJ/9vnQNLe/iiedTPD5a5bQW6zwx2ueplIZ3i+MiEj0xCf0+zpXeflR6NgNwBnNdfzZbyzgsRf38A8/3TahxRMRORHiE/oQhL5XYPMD/ZOuW3E6l541g9u//xzPv94+gYUTETn+4hX6zW+GU88Z8qKWmfEXqxbTkEvx0X9+it5SeYwNiIhMbvEKfQjO9lvWwb5X+idNr8vyF+9bzJbXDnLHD16YwMKJiBxf8Qv9Re8LhsM6V7l0wSl84C2nc/djL/PTl/ZMQMFERI6/+IV+4xx4w4Ww/quw8xdDZv3Pdy1g3rRaPn7/07R16W1dEYme+IU+wKW3BE0tf/lSePgWKHYDUJNJcefqJbS29/K/vrtpggspIjL+4hn6p78Ffv/nsOQ6+Mmd8MW3wqs/BWDxnCl89B3zefDpnXz3qR0TXFARkfEVz9AHyDfBVX8Hv/kdKBfgq5fDv38cetv5yMVvZNkbmviz72yiZX/XRJdURGTcxDf0+5x5Cdz4c7jgRlj3FbjrApIv/ZDPX7MEd/j4/U9T1tu6IhIRCn2ATC2s/D/wWz8Ixu9dxWmPfoz/vXI2T7yyj6vuepw1G1roKeoZfhGZ3BT6g522An7vMbjoT2DTGq54/N3c+ys76SmU+cS/PM2v3P4f/NVDz/FaW/dEl1RE5KiY+8lVdbFs2TJfv379RBcDXn8GvnsTvPYUnm3gYOMC/qtnNg/tbeY55nLGgvP54IXzWT63CTOb6NKKSMyZ2QZ3X3bY5RT6YyiXgiYbWv4rOAjs2gzF4MZukSQvVOawIzef6W88n4VL30p2xhshmYFECpLpgXEdFETkOFPoHw+VMux7GV7fSHHHRva8uI7c3s00+YGx10ukIBEeBJIpSGZhyulBW0DNZ8GMs4Jh/UwdIETkqIxr6JvZSuBvgCTw/9z99mHzs8DXgfOBvcA17r4tnLcY+BLQAFSA5e4+aq8lJ3Xoj8Dd2bD5eX76k0fYu2MrXi6Spkw+WWFWfYpZ9SlOrUsyozbBlKyR8FLQQfv+V2D3FujeN7CxbEN4IAgPBs1nwbQzg4NBOj9xOykiJ71xC30zSwIvAL8GtADrgGvd/dlBy9wILHb33zOz1cB73P0aM0sBTwK/6e5Pm9k04IC7j/oYzGQL/cFK5QovtXbyzI42NoWfzTsP0h0+9ZNLJ1gws4FFsxo5bWqeUxpyzEp1MLv0KtO6XiG7/0VofQ5an4fO3UM3npsCDbOg/lSonwUNMwfG608NDgy5BkjX6GpBJIaqDf1UFdtaAWx195fDDd8HXAUM7lX8KuAz4fga4O8suLt5GbDR3Z8GcPe9Ve/BJJRKJnjzqfW8+dR6Vp0/B4ByxXm5tYNNO9t4puUgm3a08cAvdtDRWxq29hzqsnOZUf8bzGjMMm9WL2enXuM0djHd99FU3kNdoZV8x27Su7ZgnbuCvgFGkq6FTE1wAMjUDgz7xhMpKHUHVxyl8FPsDoeDppWLMHspvGll8Jk+XwcUkUmumtCfDWwf9L0FeMtoy7h7yczagGnAmwA3s4eAZuA+d//LYy71JJJMGPNPqWf+KfW857xgmrvT3lti98Eedh/sZVd7D7sO9rKr7/vBHh7fUeFbB6dQKDWMuN36jHFmTRdn5tp5Q6aNOck2mtIFpiQLNCQL1FovNdZL3ntJVbqxQhd07YNiJ1RKkMpDOhcMU7ngDeVULqhGSmWD6Ths+wk8/L+CT9O88ADw60GjdanMifuHFJFxUU3oj3RqN7xOaLRlUsBbgeVAF/Cj8BLkR0NWNrsBuAHg9NNPr6JIk5uZ0ZBL05BL88YZ9aMu5+4c7Cmxr7PAvs5e9nQUwvECezsK7O3sZXdngS0dBfYe6GVvR4HSCG8PZ5IJptdlmF6fpbkhy7S6DE21GabWZGiqCcabatL90xryaZKJQT9pWwu88FDw2fBVeOILkKkP3mZ+00qYfxnUNQ8ueHDlUOwOnnbq/4RXEzXTg9ZO8026chA5waoJ/RbgtEHf5wA7R1mmJazHbwT2hdP/0933AJjZWmApMCT03f1u4G4I6vSPfDeiycxozKdpzKeZN732sMtXKk5bd5E9Hb20tvfSGg73dBTCYS+vH+xh08429ncVKZRGrh4ygyn5gYNAMFzO1GkX0jyrzJu7f8HcvY/R/OqjZLY8iGPQMAvrqyYqVtleUaYuCP8hn9MGxutOCa4+dGAQGTfVhP46YL6ZzQN2AKuB64Yt8yDwIeBnwCrgP9y9r1rnT8ysBigAbwc+P16Fl6ESCQvO2mszzD9l9CsICK4iugpl9ncV2N9ZZF9XgQNdwVXE/s4C+/qmdxbYvq+Lp7cfYH9XgWLZgSbgSuAKzrZXuTTxJPMO7MZTeSxTg+VrSWVrSedqydbUkq2pp6amntq6eupra2ioHCDftRNr2wFt24MriZ1PQdcInddY4tB7E8PvUWRqIdcYXDn0f6YMjOemBMvo4CFy+NAP6+hvAh4ieGTzHnffbGa3Aevd/UHgK8A/mtlWgjP81eG6+83sDoIDhwNr3f3fj9O+yBEwM2qzKWqzKeY0VbdO372I/Z0D1Uz7Os9lf9dKnu8osLev6qmzwN6OXvbtKtBVGP6gVg+QI5U4kyk1ZzGlJqhamnJqhunZCm9I7WeW7eEU38MUP0CeXnLeQ9Z7yFa6SVW6SZa6sUIndOwO7lEUOqH7AFTG6PgmkQ4PAI3BU07ZhmCYawzHGwem9Q2T2fC9ikz4nkV60Et36YF5ySwk1KKJTA56OUuOq+5Cmb2dwf2GfZ0F9nT0cqCrGFxhdBU50FVgf1eBA13F/um9o1Q79UkmjLpsirpsivpc8KnLJJmaLdOc7GJ6qospdDIl0Umjt1PvHdRUDlJTaidbOkiq1EGq2EGycBDrbcd6D1ZfJTWaTF3wydZDNhxm6od+z9YHB5T+8cHfw2Eqe3yvSMqlgfsr/cPuodPKheDqqK4ZamdAbfOR3bSvVIKrtoM7of11aN8JnXuD/audHmyvb5ifGhw85ZiN5yObIkctn0kyJ1PDnKaaqtfpDqudDnQV6SyUaO8p0t5ToqO3FAx7wmm9feMl9nYVeXVfifZe6OjJ0F1MErwPOPPwZUwnaUg70zK9TE/3MjXZy9RkD7Wp4CW7fKJMLlkhn6iQTZTJWZlsokzWKmSsRJYCmXIX2XIn6XIn6VInqa5OUm27SRQ7SRY7sEI7Vhn+mO4IEunwfYvaIGhTueBqIpUNPsnsoOnZ4MqjXAzCesijt33DroHHcIvdY18NjSU3BepmBAeBvoNBXXNQ/XbwNWh/LQz416BjV/CEWFUsuALrPxBMDw4EfVdkuUbINg67QgvHM3WqsjsKCn056eQzSfKZPLOmHP1byKVyhc7eMu29RTr6Dg69JTp7S3QVynQXysGwWKa7MHTavmKZHYUS3cUyPd0VugtlekvB/O5imaPrXsHJUqSObuqsmymJHpqS3UxJ9tKQ6KbRemhI9FBv3TSUu8hXeskVSmQpkqFIxnrI+EHSFEl78El5gaSXqCTSlJI5yoks5f5hPeXkdCo1OSrJLOVknkr4SK5larF0cP8lka0lmakhma0hla0llashlc6RKbaR7t5DqnsPia7WoCqtczd0tAbtUHW0Qm9bsGu5xuDlwPqZMP1N4YuDw14erJ0OvR3BFUBna/jZE35aw+l7grfUu/ZB78HgimMslhj26HE2fOQ4NzDsm5ZIBe+1VMrB0Cvg5eBJsyHTy8FBtFIODpDlYnAAKxfD76Xge6XVA1DIAAAGV0lEQVQ46D0ZCw8+g4YwdFr/36wM+ns+rCwVmLUUfuuho/kPrGoKfYmkVDJBY02Cxpr0uG7X3SmWnZ5SmZ5CmZ5ihZ5SmUKpQm+pQqFUoVAOh6UKhXK5f7x32LxieWD5HaUKrwyaNnhbvcW+Ybn/e2+43PgpAW3hp08CmIHZDNLJc8gkE6SSRjqZIJ0wamtKpBNQSeVJVxKkOox0d4L0XiOVSATLJSGV3E060UoiYRhgVk/CGjA7E7NgWiJjWBZsavBAQiphZChSW+kgX+mkptJJvtJBvtJBrtxJrtxOrtxJ2nvJeC+pSoF0pZeUF0hVekl29ZCstJEs95Io92BeBkviZuEwASTwRDi04IMlBrWVlYdMAyRTWDINiTSWDD4kU1giibnT/wR7OB5Evvd/x51EMoVZAkuEf8MSYMlwaOHfTQZPrR1nCn2RI2BmZFJGJpWgITe+B5Qj5e4UyhUqFai4h59gerkyMF7xYH6p7BTKwYFqtINJ3/dSJdh2qewUyxWK/cPh48H3UrkSrFOq0FOsUCqXKAybDkE53MHpK19QRh80r1Jxyu6UKsF+BD3XZYCp4WfySiWMZCI4cKaSfQdHCw6miQQLZzfyf5cf5zIc382LyPFiZmRTyYkuxnHXd+AqVSqUK+HBoBwM+w48fVdFxbIPXEWVB66o+ro87buyMAPDwmHfrQHr/3tlHzjg9H/cqVQGDkZ9z8D4oHdVB6YNqHhQ3mLFKVf6DqROqTL0gFksVzh96vFvWFGhLyInNTMjaZBMRP8AdyLo4WIRkRhR6IuIxIhCX0QkRhT6IiIxotAXEYkRhb6ISIwo9EVEYkShLyISIydd08pm1gq8egybmA6M0BvHpBW1/YHo7VPU9geit09R2x84dJ/e4O7Noy3c56QL/WNlZuuraVN6soja/kD09ilq+wPR26eo7Q8c/T6pekdEJEYU+iIiMRLF0L97ogswzqK2PxC9fYra/kD09ilq+wNHuU+Rq9MXEZHRRfFMX0RERhGZ0DezlWb2vJltNbObJ7o848HMtpnZM2b2lJmtn+jyHCkzu8fMdpvZpkHTpprZw2b2YjhsmsgyHqlR9ukzZrYj/J2eMrN3TmQZj4SZnWZmj5jZFjPbbGZ/GE6flL/TGPszmX+jnJn9l5k9He7TreH0eWb2RPgb/bOZZaraXhSqd8wsCbwA/BrQAqwDrnX3Zye0YMfIzLYBy9x9Uj5fbGYXAR3A1919UTjtL4F97n57eHBucvdPTmQ5j8Qo+/QZoMPdPzeRZTsaZjYTmOnuT5pZPbABeDdwPZPwdxpjf97P5P2NDKh19w4zSwOPA38I/BHwbXe/z8y+CDzt7l843Paicqa/Atjq7i+7ewG4D7hqgssUe+7+Y2DfsMlXAV8Lx79G8D/kpDHKPk1a7v6auz8ZjrcDW4DZTNLfaYz9mbQ80BF+TYcfB34VWBNOr/o3ikrozwa2D/rewiT/oUMO/MDMNpjZDRNdmHFyiru/BsH/oMCMCS7PeLnJzDaG1T+ToipkODObC5wHPEEEfqdh+wOT+Dcys6SZPQXsBh4GXgIOuHspXKTqzItK6NsI0yZ/vRVc6O5LgcuB3w+rFuTk8wXgTGAJ8Brw1xNbnCNnZnXAt4CPuvvBiS7PsRphfyb1b+TuZXdfAswhqNlYMNJi1WwrKqHfApw26PscYOcElWXcuPvOcLgbeIDgx57sdoX1rn31r7snuDzHzN13hf9TVoAvM8l+p7Ce+FvAve7+7XDypP2dRtqfyf4b9XH3A8CjwAXAFDNLhbOqzryohP46YH54NzsDrAYenOAyHRMzqw1vRGFmtcBlwKax15oUHgQ+FI5/CPjuBJZlXPSFY+g9TKLfKbxJ+BVgi7vfMWjWpPydRtufSf4bNZvZlHA8D7yD4F7FI8CqcLGqf6NIPL0DED6CdSeQBO5x989OcJGOiZmdQXB2D5ACvjHZ9snMvglcTNAa4C7gFuA7wP3A6cAvgavdfdLcGB1lny4mqDZwYBvwu3314Sc7M3sr8BjwDFAJJ3+KoB580v1OY+zPtUze32gxwY3aJMGJ+v3ufluYEfcBU4FfAB90997Dbi8qoS8iIocXleodERGpgkJfRCRGFPoiIjGi0BcRiRGFvohIjCj0RURiRKEvIhIjCn0RkRj5/wilScDNdO2KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the network\n",
    "history = model.fit(x_training, y_training, epochs=30, batch_size=72, validation_data=(x_validation, y_validation), verbose=1, shuffle=False)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see in the graph above, that the validation loss hits a floor around the 25th epoch - and while the training loss does decrease (albeit at a slow rate) the validation loss does not - indicating slight but small overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left;\"><span style=\"text-decoration: underline;\"><strong>MODEL EVALUATION</strong></span></p>\n",
    "<p>Below I use this model to create a prediction - and after the prediction is de-scaled back to the original temperature values, my predicted temperatures are added to the template and saved to disk.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with my model\n",
    "pred = model.predict(x_testing)\n",
    "\n",
    "# De-scale the predicted values into normal Celcius values\n",
    "inv_pred = pred*8.01432 + 10.25075    #These values were provided by the Professor, but may not be 100% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date time</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2015 00:00:00</td>\n",
       "      <td>1.462562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02.01.2015 01:00:00</td>\n",
       "      <td>1.772528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02.01.2015 02:00:00</td>\n",
       "      <td>1.692197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02.01.2015 03:00:00</td>\n",
       "      <td>1.889138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02.01.2015 04:00:00</td>\n",
       "      <td>2.494550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date time  temperature\n",
       "0  02.01.2015 00:00:00     1.462562\n",
       "1  02.01.2015 01:00:00     1.772528\n",
       "2  02.01.2015 02:00:00     1.692197\n",
       "3  02.01.2015 03:00:00     1.889138\n",
       "4  02.01.2015 04:00:00     2.494550"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the submission template and save it to disk\n",
    "submission = pd.read_csv(\"sample_submission_2019spring.txt\")\n",
    "submission.temperature = inv_pred\n",
    "submission.to_csv('model1d.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
